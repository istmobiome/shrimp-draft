{
  "hash": "7cfa00fde9d1e75de77c21e8a009d56c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Portal\"\nlisting: \n  id: med-listing\n  contents: listings/data-med.yml\nmetadata-files: \n  - listings/_metadata.yml\n---\n\n::: column-body-outset-right\n\n::: {.cell}\n\n:::\n\n\n\n\nQuick access to fastq sequence files, processing scripts, and curated datasets. If you want to process the data yourself, select a pipeline, download the sequence data and processing scripts, and run the workflow.  \n\n:::\n\n::: column-body-outset-right\n```{=html}\n\n<style type=\"text/css\">\n/* keep global nav-tabs tweaks */\n.nav-tabs {\n  margin-top: 0.5rem;\n  border-bottom: none;\n}\n\n.callout {\n  margin-top: 0;\n}\n\n/* --------------------- */\n/* Scoped only to #index-chooser */\n#index-chooser .nav-link {\n  text-align: center;\n  margin-right: 15px;\n  margin-top: 10px;\n  width: 155px;\n  font-size: 1em; /* changed from 0.9 to 1.0 by jjs */\n  font-weight: 600;\n  display: flex;\n  flex-direction: column;\n  justify-content: center;  /* vertically center content */\n  align-items: center;      /* horizontally center content */\n  min-height: 6rem;   \n}\n\n#index-chooser .nav-link,\n#index-chooser .nav-link.active,\n#index-chooser .nav-item.show .nav-link {\n  border: 1px solid rgb(222, 226, 230);\n  border-radius: 10px;\n  color: rgb(80,146,221);\n}\n\n#index-chooser .nav-link:hover {\n   border-color: rgb(80,146,221);\n   border-width: 1px;\n} \n\n#index-chooser .nav-link.active,\n#index-chooser .nav-item.show .nav-link {\n  border-color: rgb(80,146,221);\n  border-width: 2px;\n}\n\n#index-chooser .nav-link i {\n  display: block;\n  font-size: 3rem;\n  color: rgb(80,146,221);\n  margin-bottom: 5px;\n}\n\n#index-chooser .nav-link img {\n  display: block;\n  max-width: 100%;    /* don’t exceed box width */\n  max-height: 4rem;   /* don’t exceed 4rem height */\n  width: auto;        /* keep aspect ratio */\n  height: auto;       /* keep aspect ratio */\n  margin: 0 auto 5px auto; /* center + bottom margin */\n}\n/* --------------------- */\n\n/* keep global listing tweaks */\n.quarto-listing {\n  margin-top: 2em;\n}\n\n.quarto-listing .listing-name,\n.quarto-listing .listing-author {\n  white-space: nowrap;\n}\n\n.quarto-listing .listing-actions-group h3 {\n  margin-top: 0;\n}\n</style>\n\n\n<ul id=\"index-chooser\" class=\"nav nav-tabs\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-dada2.html\">\n      <img src=\"/images/dada2_icon.png\" alt=\"dada2 icon\">\n      16S rRNA Dada2 processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-otu.html\">\n      <img src=\"/images/mothur_icon.png\" alt=\"mothur icon\">\n      16S rRNA OTU processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-med.html\">\n      <img src=\"/images/med_icon.png\" alt=\"med icon\">\n      16S rRNA MED processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-mg.html\">\n      <img src=\"/images/anvio_icon.png\" alt=\"anvio icon\">\n      Metagenomic processing\n    </a>\n  </li>\n</ul>\n\n<script type=\"text/javascript\">\ndocument.addEventListener(\"DOMContentLoaded\", function() {\n  // get file name\n  const filename = window.location.pathname.split(\"/\").slice(-1)[0];\n\n  // latch active\n  const toolLinks = window.document.querySelectorAll(\"#index-chooser a\");\n  for (const tool of toolLinks) {\n    if (filename && filename !== \"index.html\") {\n      if (tool.href.endsWith(filename)) {\n        tool.classList.add(\"active\");\n      } \n    } else {\n      if (tool.href.endsWith(\"listing-filters.html\")) {\n        tool.classList.add(\"active\");\n      }\n    }\n  }\n  \n  // move heading into table\n  document.querySelector(\".listing-actions-group\").prepend(document.querySelector(\"h3.unlisted\"));\n});\n\n</script>\n```\n:::\n\n\n\n<br/>\n\n## Data & Scripts {.unlisted}\n\n::: {.callout-note icon=false}\n\n## A note about curated data\n\nCurated means that after processing, the data has been cleaned of unwanted taxa (e.g., NA kingdoms, potential contaminants, etc). Negative control & low-count samples have also been removed. These data are ready for downstream analysis.\n:::\n\n\n\nHere we provide two options for processing sequence data--the detailed pipeline (listed in the table) and a [quick set of commands linked below](#med-processing). \n\n::: {#med-listing .column-body-outset-right}\n:::\n\n::: column-body-outset-right\n\n## MED Processing \n\nProcessing scripts for [Minimum Entropy Decomposition (MED)](https://merenlab.org/2014/11/04/med/) analysis. The pipeline begins with the output fasta and count files from the `align.seqs` portion of the mothur OTU pipeline. From there we use R and mothur to remove negative control samples, check for chimera, and run taxonomic classifications. It is important to note that the MED workflow does not `precluster` sequences (as in the mothur pipeline) because MED relies on every sequence (including redundant reads) for the analysis. This pipeline has four main steps:\n\n1. run the mothur workflow.   \n2. modify and run the `mothur2oligo.sh` script. This script transforms the mothur output to appropriate format for MED. It must be run in the mothur environment because the script uses mothur. We need access to the following mothur files to run this script. \n    i. **taxonomy file**: `final_med.taxonomy`   \n    ii. **count file**: `final_med.count_table`   \n    iii. **fasta file**: `final_med.fasta`   \n3. trim uninformative columns from alignment (in the MED environment)     \n4. run the MED command\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"mothur processing script for MED analysis\"}\n########################################################################\n#$ export DATA=01_TRIMMED_DATA/\n#$ export TYPE=gz\n#$ export PROC=30\n\n#$ export REF_LOC=reference_dbs\n#$ export TAXREF_FASTA=gsrdb.fasta\n#$ export TAXREF_TAX=gsrdb.tax\n#$ export ALIGNREF=silva.v4.fasta\n\n#$ export CONTAMINENTS=Chloroplast-Mitochondria-unknown-Eukaryota\n###############################################################################\n#### THIS PIPELINE BEGINS AFTER ALIGN.SEQS (AND ASSOCIATED SCREENING STEP)\n#### IN THE MOTHUR OTU PIPLINE. IF YOU HAVE NO USE FOR STRICT OTU ANAYSIS\n#### SIMPLY UNCOMMENT THE MOTHUR COMMANDS BELOW TO RUN THE FULL PIPELINE HERE\n###############################################################################\nset.dir(output=pipelineFiles_med/)\n###############################################################################\n# UNCOMMENT FROM HERE....\n###############################################################################\n#make.file(inputdir=$DATA/, type=$TYPE, prefix=shrimp)\n########################################################################\n#### had to fix shimp.files bc mothur splits name at first underscore (_)\n########################################################################\n#make.contigs(file=shrimp.files, processors=$PROC)\n#summary.seqs(fasta=shrimp.trim.contigs.fasta, count=shrimp.contigs.count_table, processors=$PROC)\n#count.groups(count=shrimp.contigs.count_table)\n#screen.seqs(fasta=current, count=current, maxambig=0, minlength=252, maxlength=254, maxhomop=6, processors=$PROC)\n#summary.seqs(fasta=current, count=current, processors=$PROC)\n#count.groups(count=current)\n#unique.seqs(fasta=current, count=current)\n#summary.seqs(count=current, processors=$PROC)\n########################################################################\n#### Aligning reads\n########################################################################\n# https://mothur.org/wiki/silva_reference_files/\n#### Prep reference file\n#pcr.seqs(fasta=$REF_LOC/silva.seed_v138_2.align, start=13862, end=23445, keepdots=F, processors=$PROC)\n#rename.file(input=pipelineFiles/silva.seed_v138_2.pcr.align, new=pipelineFiles/$ALIGNREF)\n#summary.seqs(fasta=pipelineFiles/$ALIGNREF, processors=$PROC)\n#### Align reads\n#align.seqs(fasta=shrimp.trim.contigs.good.unique.fasta, reference=pipelineFiles/$ALIGNREF, processors=$PROC)\n#summary.seqs(fasta=shrimp.trim.contigs.good.unique.align, count=shrimp.trim.contigs.good.count_table, processors=$PROC)\n########################################################################\n#### Further processing\n########################################################################\n#screen.seqs(fasta=current, count=current, start=1, end=9583, processors=$PROC)\n#summary.seqs(fasta=current, count=current, processors=$PROC)\n#count.groups(count=current)\n#filter.seqs(fasta=current, vertical=T, trump=., processors=$PROC)\n#unique.seqs(fasta=current, count=current)\n#summary.seqs(fasta=current, count=current, processors=$PROC)\n###############################################################################\n# ....TO HERE\n###############################################################################\n#### Copy mothur output files\n########################################################################\nsystem(cp pipelineFiles/shrimp.trim.contigs.good.unique.good.filter.unique.fasta pipelineFiles_med/)\nsystem(cp pipelineFiles/shrimp.trim.contigs.good.unique.good.filter.count_table pipelineFiles_med/)\n########################################################################\n#### Remove Negative Control samples (files generated in R)\n########################################################################\n\n########## IN R ########################################################\n#tmp_accnos <- readr::read_delim(here(work_here, \"nc_screen/shrimp.files\"), delim = \"\\t\", col_names = FALSE)\n#tmp_accnos[, 2:3] <- NULL\n#tmp_accnos <- tmp_accnos[grepl(\"Control_\", tmp_accnos$X1), ]\n#readr::write_delim(tmp_accnos, file = here(work_here, \"nc_screen/nc_samples.accnos\"), col_names = FALSE)\n########################################################################\nget.groups(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.fasta, count=shrimp.trim.contigs.good.unique.good.filter.count_table, accnos=nc_samples.accnos)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.pick.fasta, new=nc.fasta)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.pick.count_table, new=nc.count_table)\nsummary.seqs(fasta=nc.fasta, count=nc.count_table, processors=$PROC)\nlist.seqs(count=nc.count_table)\ncount.seqs(count=nc.count_table, compress=f)\nget.seqs(accnos=nc.accnos, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.fasta, count=shrimp.trim.contigs.good.unique.good.filter.count_table)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.pick.fasta, new=subset.fasta)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.pick.count_table, new=subset.count_table)\ncount.seqs(count=subset.count_table, compress=f)\n########################################################################\n########## IN R ########################################################\n########################################################################\n#full_count_tab <- readr::read_delim(here(work_here, \"nc_screen/subset.full.count_table\"), delim = \"\\t\", col_names = TRUE)\n#control_cols     <- grep(\"^Control_\", names(full_count_tab), value = TRUE)\n#noncontrol_cols  <- setdiff(names(full_count_tab)[-(1:2)], control_cols)\n#read_totals <- full_count_tab %>%\n#  rowwise() %>%\n#  mutate(\n#    total_reads_nc   = sum(c_across(all_of(control_cols)), na.rm = TRUE),\n#    total_reads_non_nc = sum(c_across(all_of(noncontrol_cols)), na.rm = TRUE)\n#  ) %>%\n#  ungroup() %>%\n#  select(1, 2, total_reads_nc, total_reads_non_nc)\n#read_totals <- read_totals %>% dplyr::rename(\"total_reads\" = 2)\n#tmp_read_totals <- read_totals %>% dplyr::mutate(perc_reads_in_nc = 100*(total_reads_nc / (total_reads_nc + total_reads_non_nc)), .after = \"total_reads_non_nc\")\n#tmp_read_totals$perc_reads_in_nc <- round(tmp_read_totals$perc_reads_in_nc, digits = 6)\n#control_cols     <- grep(\"^Control_\", names(full_count_tab), value = TRUE)\n#noncontrol_cols  <- setdiff(names(full_count_tab)[-(1:2)], control_cols)\n# rowwise tally of non-zero columns\n#samp_totals <- full_count_tab %>%\n#  rowwise() %>%\n#  mutate(\n#    num_nc_samp     = sum(c_across(all_of(control_cols)) != 0, na.rm = TRUE),\n#    num_non_nc_samp = sum(c_across(all_of(noncontrol_cols)) != 0, na.rm = TRUE)\n#  ) %>%\n#  ungroup() %>%\n#  select(1, num_nc_samp, num_non_nc_samp)\n#samp_totals$total_samp <- samp_totals$num_nc_samp + samp_totals$num_non_nc_samp\n#samp_totals <- samp_totals %>%  dplyr::relocate(\"total_samp\", .after = \"Representative_Sequence\")\n#samp_totals <- samp_totals %>% dplyr::mutate(perc_nc_samp = 100*( num_nc_samp / (num_nc_samp + num_non_nc_samp)), .after = \"num_non_nc_samp\")\n#nc_check <- dplyr::left_join(tmp_read_totals, samp_totals, by = \"Representative_Sequence\")\n#write_delim(nc_check, here(work_here, \"nc_screen/reads_in_nc_samples.txt\"), delim = \"\\t\")\n#nc_remove <- nc_check %>% filter(perc_reads_in_nc > 10 | perc_nc_samp > 10)\n#nc_remain <- dplyr::anti_join(nc_check, nc_remove)\n#rem_nc_reads <- sum(nc_remove$total_reads_nc)\n#rem_sam_reads <- sum(nc_remove$total_reads_non_nc)\n#per_reads_rem <- round(100*( rem_nc_reads / (rem_nc_reads + rem_sam_reads)), digits = 3)\n#ret_nc_reads <- sum(nc_remain$total_reads_nc)\n#ret_sam_reads <- sum(nc_remain$total_reads_non_nc)\n#per_reads_ret <- round(100*( ret_nc_reads / (ret_nc_reads + ret_sam_reads)), digits = 3)\n\n########################################################################\nremove.seqs(accnos=nc_repseq_remove.accnos, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.fasta, count=shrimp.trim.contigs.good.unique.good.filter.count_table)\ncount.groups(count=shrimp.trim.contigs.good.unique.good.filter.pick.count_table)\n########################################################################\n########## IN R ########################################################\n########################################################################\n#tmp_before <- read_tsv(here(work_here, \"nc_screen/shrimp.trim.contigs.good.unique.good.filter.count.summary\"), col_names = FALSE, col_select = 1)\n#tmp_after <- read_tsv(here(work_here, \"nc_screen/shrimp.trim.contigs.good.unique.good.filter.pick.count.summary\"), col_names = FALSE, col_select = 1)\n#tmp_nc_lost <- anti_join(tmp_before, tmp_after)\n#tmp_nc_lost$X1\n#nc_to_remove <- semi_join(tmp_before, tmp_after)\n#nc_to_remove <- nc_to_remove %>% dplyr::filter(stringr::str_starts(X1, \"Control\")) \n#readr::write_delim(nc_to_remove, file = here(work_here, \"nc_screen/nc_samples_remove.accnos\"), col_names = FALSE)\n########################################################################\nremove.groups(count=shrimp.trim.contigs.good.unique.good.filter.pick.count_table, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.fasta, accnos=nc_samples_remove.accnos)\n########################################\n### NEGATIVE CONTROLS Should be GONE ###\n########################################\nsummary.seqs(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.count_table, processors=$PROC)\ncount.groups(count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.count_table)\nchimera.vsearch(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.count_table, dereplicate=t, processors=$PROC)\nsummary.seqs(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.count_table, processors=$PROC)\ncount.groups(count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.count_table)\nclassify.seqs(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.count_table, reference=reference_dbs/gsrdb.fasta, taxonomy=reference_dbs/gsrdb.tax, processors=$PROC)\nremove.lineage(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.count_table, taxonomy=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.gsrdb.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Eukaryota)\nsummary.seqs(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.pick.count_table, processors=$PROC)\nsummary.tax(taxonomy=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.gsrdb.wang.pick.taxonomy, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.pick.count_table)\ncount.groups(count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.pick.count_table)\n############################################\n### PROCEED To  mothur2oligo.sh pipeline ###\n### MUST BE RUN IN MOTHUR ENVIRONMENT  #####\n############################################\n\n```\n:::\n\n\nOnce you have the script and data you simply run the pipeline like so. \n\n\n::: {.cell}\n\n```{.zsh .cell-code}\nmothur med_batchfile_processing\n```\n:::\n\n\nOnce the mothur portion of the workflow is complete, the script [`mothur2oligo.sh`](https://github.com/DenefLab/MicrobeMiseq/tree/master/mothur2oligo) needs to be run in the `mothur` environment and modified for your specific purposes. You should not need to modify the associated `renamer.pl` script but it does need to be in the same location as `mothur2oligo.sh`. You can download the modified script we used in the table above. \n\n\n::: {.cell}\n\n```{.bash .cell-code}\nbash mothur2oligo.sh\n```\n:::\n\n\n::: panel-tabset\n\n## mothur2oligo\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Expand for the `mothur2oligo.sh` script\"}\nconda activate mothur\n# USAGE: sh mothur2oligo.sh\n# This is a shell script for transforming mothur output to appropriate format for \n# A. murat Eren's oligotyping pipeline \n\n## Set variables\n\n# Adjust the file names to your own study - these are the files from the mothur SOP\ntaxonomy=\"final_med.taxonomy\"\nfasta=\"final_med.fasta\"\ncount=\"final_med.count_table\"\nprocessors=3\n\n# Set the taxon you want to select, separate taxonomic levels with \";\" \n# Do not touch inner and outer quotes\ntaxon=\"'Bacteria;-Archaea;'\"\n\n\n################################\n########## Script  #############\n################################\n\nredundantFasta=$(echo ${fasta}.pick.redundant.fasta | sed 's/.fasta//')\ngroups=$(echo ${count}.pick.redundant.groups | sed 's/.count_table//') \n\n# Call mothur commands for generating deuniqued fasta file for a specific lineage\nmothur \"#set.current(processors=$processors); get.lineage(taxonomy=$taxonomy, taxon=$taxon, count=$count); list.seqs(count=current); get.seqs(accnos=current, fasta=$fasta); deunique.seqs(fasta=current, count=current)\"\n\n# Replace all \"_\" in fasta header with a \":\"\ncat $groups | sed 's/_/:/g' > intermediate1\n# Make a file which maps sample names to sequence headers\npaste $groups intermediate1 | awk 'BEGIN{FS=\"\\t\"}{print $1\"\\t\"$2\"_\"$3}' > intermediate2\n\n# Perl script to rename the headers of the fasta to include the sample name at the beginning followed by a \"_\"\nperl renamer.pl $redundantFasta intermediate2 \n\n```\n:::\n\n\n## renamer\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"and the companion `renamer.pl` script\"}\nconda activate mothur\n#! /usr/bin/perl\n#from http://www.perlmonks.org/?node_id=975419\n\nuse strict;\nuse warnings;\n\n@ARGV == 2 or die \"usage: $0 <multifasta file> <header replacement fil\n+e>\\n\";\n\nmy ( $fasta_file, $header_file ) = @ARGV;\nmy $destination = $fasta_file . '_headers-replaced.fasta';\n\nopen IN2, '<', $header_file or die \"Can't read from tab-delimited head\n+er replacement file $header_file: $!\\n\";\n\nmy %head_seqs;\nwhile ( <IN2> ) {\n    chomp;\n    my ( $old, $new ) = split /\\t/;\n    $head_seqs{ $old } = $new;\n    }\nclose IN2;\n\nopen IN1, '<', $fasta_file or die \"Can't read from multifasta file wit\n+h alternating lines of headers and sequences $fasta_file: $!\\n\";\n\nopen OUT, '>', $destination or die \"Can't write to file $destination: \n+$!\\n\";    \n\nwhile ( <IN1> ) {\n    if ( /^>(.+)$/ && exists $head_seqs{ $1 } ) {\n        $_ = \">$head_seqs{ $1 }\\n\";\n        }\n    print OUT $_;\n    }\nclose IN1;\nclose OUT;\n\n```\n:::\n\n\n:::\n\nGreat. Now within the oligotype/MED environment run the following commands for the MED analysis. You will need the `mapping.txt` file  linked above for this step. \n\n\n::: {.cell}\n\n```{.zsh .cell-code}\nconda activate oligotyping\no-trim-uninformative-columns-from-alignment \\\n        final_med.pick.redundant.fasta_headers-replaced.fasta\n\ndecompose final_med.pick.redundant.fasta_headers-replaced.fasta-TRIMMED \\\n        -E mapping.txt \\\n        --output-directory MED \\\n        --number-of-threads 24 \\\n        --skip-gen-figures\n```\n:::\n\n\nIn the resources listed above, we include a table that summarizes read changes for each sample through the pipeline.\n\n:::\n\n\n::: {.column-body-outset-right}\n\n\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n#### Detailed Session Info {.appendix}\n\n{{< dstart summary=\"Expand to see Session Info\" >}}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.5.1 (2025-06-13)\n os       macOS Ventura 13.7.8\n system   x86_64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2025-10-03\n pandoc   3.6.3 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/x86_64/ (via rmarkdown)\n quarto   1.8.25 @ /Applications/quarto/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package                  * version   date (UTC) lib source\n Biobase                  * 2.68.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n BiocGenerics             * 0.54.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n Biostrings               * 2.76.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n downloadthis             * 0.5.0     2025-09-26 [1] Github (fmmattioni/downloadthis@18e3e5a)\n dplyr                    * 1.1.4     2023-11-17 [1] CRAN (R 4.5.0)\n fontawesome              * 0.5.3     2024-11-16 [1] CRAN (R 4.5.0)\n forcats                  * 1.0.0     2023-01-29 [1] CRAN (R 4.5.0)\n fs                       * 1.6.6     2025-04-12 [1] CRAN (R 4.5.0)\n generics                 * 0.1.4     2025-05-09 [1] CRAN (R 4.5.0)\n GenomeInfoDb             * 1.44.2    2025-08-18 [1] Bioconductor 3.21 (R 4.5.1)\n GenomicRanges            * 1.60.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n ggplot2                  * 4.0.0     2025-09-11 [1] CRAN (R 4.5.1)\n here                     * 1.0.2     2025-09-15 [1] CRAN (R 4.5.1)\n htmltools                * 0.5.8.1   2024-04-04 [1] CRAN (R 4.5.0)\n IRanges                  * 2.42.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n lubridate                * 1.9.4     2024-12-08 [1] CRAN (R 4.5.0)\n magrittr                 * 2.0.4     2025-09-12 [1] CRAN (R 4.5.1)\n MatrixGenerics           * 1.20.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n matrixStats              * 1.5.0     2025-01-07 [1] CRAN (R 4.5.0)\n mia                      * 1.15.6    2024-11-22 [1] Bioconductor 3.21 (R 4.5.0)\n microbiome               * 1.30.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n microeco                 * 1.15.0    2025-05-18 [1] CRAN (R 4.5.0)\n microViz                 * 0.12.7    2025-08-01 [1] https://david-barnett.r-universe.dev (R 4.5.1)\n MultiAssayExperiment     * 1.34.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n pander                   * 0.6.6     2025-03-01 [1] CRAN (R 4.5.0)\n phyloseq                 * 1.52.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n purrr                    * 1.1.0     2025-07-10 [1] CRAN (R 4.5.1)\n R.methodsS3              * 1.8.2     2022-06-13 [1] CRAN (R 4.5.0)\n R.oo                     * 1.27.1    2025-05-02 [1] CRAN (R 4.5.0)\n R.utils                  * 2.13.0    2025-02-24 [1] CRAN (R 4.5.0)\n reactable                * 0.4.4     2023-03-12 [1] CRAN (R 4.5.0)\n reactablefmtr            * 2.0.0     2022-03-16 [1] CRAN (R 4.5.0)\n readr                    * 2.1.5     2024-01-10 [1] CRAN (R 4.5.0)\n S4Vectors                * 0.46.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n seqinr                   * 4.2-36    2023-12-08 [1] CRAN (R 4.5.0)\n sessioninfo              * 1.2.3     2025-02-05 [1] CRAN (R 4.5.0)\n SingleCellExperiment     * 1.30.1    2025-05-05 [1] Bioconductor 3.21 (R 4.5.0)\n stringr                  * 1.5.2     2025-09-08 [1] CRAN (R 4.5.1)\n SummarizedExperiment     * 1.38.1    2025-04-28 [1] Bioconductor 3.21 (R 4.5.0)\n tibble                   * 3.3.0     2025-06-08 [1] CRAN (R 4.5.0)\n tidyr                    * 1.3.1     2024-01-24 [1] CRAN (R 4.5.0)\n tidyverse                * 2.0.0     2023-02-22 [1] CRAN (R 4.5.0)\n tinytable                * 0.13.0.10 2025-09-07 [1] https://vincentarelbundock.r-universe.dev (R 4.5.1)\n TreeSummarizedExperiment * 2.16.1    2025-05-08 [1] Bioconductor 3.21 (R 4.5.0)\n XVector                  * 0.48.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n zip                      * 2.3.3     2025-05-13 [1] CRAN (R 4.5.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.5-x86_64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n======   Devtools Session info   ===================================\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n package                  * version   date (UTC) lib source\n Biobase                  * 2.68.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n BiocGenerics             * 0.54.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n Biostrings               * 2.76.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n downloadthis             * 0.5.0     2025-09-26 [1] Github (fmmattioni/downloadthis@18e3e5a)\n dplyr                    * 1.1.4     2023-11-17 [1] CRAN (R 4.5.0)\n fontawesome              * 0.5.3     2024-11-16 [1] CRAN (R 4.5.0)\n forcats                  * 1.0.0     2023-01-29 [1] CRAN (R 4.5.0)\n fs                       * 1.6.6     2025-04-12 [1] CRAN (R 4.5.0)\n generics                 * 0.1.4     2025-05-09 [1] CRAN (R 4.5.0)\n GenomeInfoDb             * 1.44.2    2025-08-18 [1] Bioconductor 3.21 (R 4.5.1)\n GenomicRanges            * 1.60.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n ggplot2                  * 4.0.0     2025-09-11 [1] CRAN (R 4.5.1)\n here                     * 1.0.2     2025-09-15 [1] CRAN (R 4.5.1)\n htmltools                * 0.5.8.1   2024-04-04 [1] CRAN (R 4.5.0)\n IRanges                  * 2.42.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n lubridate                * 1.9.4     2024-12-08 [1] CRAN (R 4.5.0)\n magrittr                 * 2.0.4     2025-09-12 [1] CRAN (R 4.5.1)\n MatrixGenerics           * 1.20.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n matrixStats              * 1.5.0     2025-01-07 [1] CRAN (R 4.5.0)\n mia                      * 1.15.6    2024-11-22 [1] Bioconductor 3.21 (R 4.5.0)\n microbiome               * 1.30.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n microeco                 * 1.15.0    2025-05-18 [1] CRAN (R 4.5.0)\n microViz                 * 0.12.7    2025-08-01 [1] https://david-barnett.r-universe.dev (R 4.5.1)\n MultiAssayExperiment     * 1.34.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n pander                   * 0.6.6     2025-03-01 [1] CRAN (R 4.5.0)\n phyloseq                 * 1.52.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n purrr                    * 1.1.0     2025-07-10 [1] CRAN (R 4.5.1)\n R.methodsS3              * 1.8.2     2022-06-13 [1] CRAN (R 4.5.0)\n R.oo                     * 1.27.1    2025-05-02 [1] CRAN (R 4.5.0)\n R.utils                  * 2.13.0    2025-02-24 [1] CRAN (R 4.5.0)\n reactable                * 0.4.4     2023-03-12 [1] CRAN (R 4.5.0)\n reactablefmtr            * 2.0.0     2022-03-16 [1] CRAN (R 4.5.0)\n readr                    * 2.1.5     2024-01-10 [1] CRAN (R 4.5.0)\n S4Vectors                * 0.46.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n seqinr                   * 4.2-36    2023-12-08 [1] CRAN (R 4.5.0)\n sessioninfo              * 1.2.3     2025-02-05 [1] CRAN (R 4.5.0)\n SingleCellExperiment     * 1.30.1    2025-05-05 [1] Bioconductor 3.21 (R 4.5.0)\n stringr                  * 1.5.2     2025-09-08 [1] CRAN (R 4.5.1)\n SummarizedExperiment     * 1.38.1    2025-04-28 [1] Bioconductor 3.21 (R 4.5.0)\n tibble                   * 3.3.0     2025-06-08 [1] CRAN (R 4.5.0)\n tidyr                    * 1.3.1     2024-01-24 [1] CRAN (R 4.5.0)\n tidyverse                * 2.0.0     2023-02-22 [1] CRAN (R 4.5.0)\n tinytable                * 0.13.0.10 2025-09-07 [1] https://vincentarelbundock.r-universe.dev (R 4.5.1)\n TreeSummarizedExperiment * 2.16.1    2025-05-08 [1] Bioconductor 3.21 (R 4.5.0)\n XVector                  * 0.48.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n zip                      * 2.3.3     2025-05-13 [1] CRAN (R 4.5.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.5-x86_64/Resources/library\n * ── Packages attached to the search path.\n```\n\n\n:::\n:::\n\n\n{{< dstop >}}\n\n#### Last updated on {.appendix}\n\n2025-10-03\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}