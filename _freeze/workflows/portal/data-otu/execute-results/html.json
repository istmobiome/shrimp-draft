{
  "hash": "faef64c10def3d41bf16bc0931a78178",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Portal\"\nlisting: \n  id: otu-listing\n  contents: listings/data-otu.yml\nmetadata-files: \n  - listings/_metadata.yml\n---\n\n::: column-body-outset-right\n\n::: {.cell}\n\n:::\n\n\n\n\nQuick access to fastq sequence files, processing scripts, and curated datasets. If you want to process the data yourself, select a pipeline, download the sequence data and processing scripts, and run the workflow.  \n\n:::\n\n::: column-body-outset-right\n```{=html}\n\n<style type=\"text/css\">\n/* keep global nav-tabs tweaks */\n.nav-tabs {\n  margin-top: 0.5rem;\n  border-bottom: none;\n}\n\n.callout {\n  margin-top: 0;\n}\n\n/* --------------------- */\n/* Scoped only to #index-chooser */\n#index-chooser .nav-link {\n  text-align: center;\n  margin-right: 15px;\n  margin-top: 10px;\n  width: 155px;\n  font-size: 1em; /* changed from 0.9 to 1.0 by jjs */\n  font-weight: 600;\n  display: flex;\n  flex-direction: column;\n  justify-content: center;  /* vertically center content */\n  align-items: center;      /* horizontally center content */\n  min-height: 6rem;   \n}\n\n#index-chooser .nav-link,\n#index-chooser .nav-link.active,\n#index-chooser .nav-item.show .nav-link {\n  border: 1px solid rgb(222, 226, 230);\n  border-radius: 10px;\n  color: rgb(80,146,221);\n}\n\n#index-chooser .nav-link:hover {\n   border-color: rgb(80,146,221);\n   border-width: 1px;\n} \n\n#index-chooser .nav-link.active,\n#index-chooser .nav-item.show .nav-link {\n  border-color: rgb(80,146,221);\n  border-width: 2px;\n}\n\n#index-chooser .nav-link i {\n  display: block;\n  font-size: 3rem;\n  color: rgb(80,146,221);\n  margin-bottom: 5px;\n}\n\n#index-chooser .nav-link img {\n  display: block;\n  max-width: 100%;    /* don’t exceed box width */\n  max-height: 4rem;   /* don’t exceed 4rem height */\n  width: auto;        /* keep aspect ratio */\n  height: auto;       /* keep aspect ratio */\n  margin: 0 auto 5px auto; /* center + bottom margin */\n}\n/* --------------------- */\n\n/* keep global listing tweaks */\n.quarto-listing {\n  margin-top: 2em;\n}\n\n.quarto-listing .listing-name,\n.quarto-listing .listing-author {\n  white-space: nowrap;\n}\n\n.quarto-listing .listing-actions-group h3 {\n  margin-top: 0;\n}\n</style>\n\n\n<ul id=\"index-chooser\" class=\"nav nav-tabs\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-dada2.html\">\n      <img src=\"/images/dada2_icon.png\" alt=\"dada2 icon\">\n      16S rRNA Dada2 processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-otu.html\">\n      <img src=\"/images/mothur_icon.png\" alt=\"mothur icon\">\n      16S rRNA OTU processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-med.html\">\n      <img src=\"/images/med_icon.png\" alt=\"med icon\">\n      16S rRNA MED processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-mg.html\">\n      <img src=\"/images/anvio_icon.png\" alt=\"anvio icon\">\n      Metagenomic processing\n    </a>\n  </li>\n</ul>\n\n<script type=\"text/javascript\">\ndocument.addEventListener(\"DOMContentLoaded\", function() {\n  // get file name\n  const filename = window.location.pathname.split(\"/\").slice(-1)[0];\n\n  // latch active\n  const toolLinks = window.document.querySelectorAll(\"#index-chooser a\");\n  for (const tool of toolLinks) {\n    if (filename && filename !== \"index.html\") {\n      if (tool.href.endsWith(filename)) {\n        tool.classList.add(\"active\");\n      } \n    } else {\n      if (tool.href.endsWith(\"listing-filters.html\")) {\n        tool.classList.add(\"active\");\n      }\n    }\n  }\n  \n  // move heading into table\n  document.querySelector(\".listing-actions-group\").prepend(document.querySelector(\"h3.unlisted\"));\n});\n\n</script>\n```\n:::\n\n\n\n<br/>\n\n## Data & Scripts {.unlisted}\n\n::: {.callout-note icon=false}\n\n## A note about curated data\n\nCurated means that after processing, the data has been cleaned of unwanted taxa (e.g., NA kingdoms, potential contaminants, etc). Negative control & low-count samples have also been removed. These data are ready for downstream analysis.\n:::\n\n\n\nHere we provide two options for processing sequence data--the detailed pipeline (listed in the table) and a [quick set of commands linked below](#otu-processing). \n\n::: {#otu-listing .column-body-outset-right}\n:::\n\n::: column-body-outset-right\n\n## OTU Processing \n\nProcessing scripts for OTU analysis using [mothur](https://mothur.org/). All steps for processing are contained within a single [mothur batchfile](https://mothur.org/wiki/batch_mode/).\n\n### Scripts\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for mothur OTU analysis\"}\n########################################################################\n#$ export DATA=01_TRIMMED_DATA/\n#$ export TYPE=gz\n#$ export PROC=30\n\n#$ export REF_LOC=reference_dbs\n#$ export TAXREF_FASTA=gsrdb.fasta\n#$ export TAXREF_TAX=gsrdb.tax\n#$ export ALIGNREF=silva.v4.fasta\n\n#$ export CONTAMINENTS=Chloroplast-Mitochondria-unknown-Eukaryota\n########################################################################\nset.dir(output=pipelineFiles/)\nmake.file(inputdir=$DATA/, type=$TYPE, prefix=shrimp)\n########################################################################\n#### had to fix shimp.files bc mothur splits name at first underscore (_)\n########################################################################\nmake.contigs(file=shrimp.files, processors=$PROC)\nsummary.seqs(fasta=shrimp.trim.contigs.fasta, count=shrimp.contigs.count_table, processors=$PROC)\ncount.groups(count=shrimp.contigs.count_table)\nscreen.seqs(fasta=current, count=current, maxambig=0, minlength=252, maxlength=254, maxhomop=6, processors=$PROC)\nsummary.seqs(fasta=current, count=current, processors=$PROC)\ncount.groups(count=current)\nunique.seqs(fasta=current, count=current)\nsummary.seqs(count=current, processors=$PROC)\n########################################################################\n#### Aligning reads\n########################################################################\n# https://mothur.org/wiki/silva_reference_files/\n#### Prep reference file\npcr.seqs(fasta=$REF_LOC/silva.seed_v138_2.align, start=13862, end=23445, keepdots=F, processors=$PROC)\nrename.file(input=pipelineFiles/silva.seed_v138_2.pcr.align, new=pipelineFiles/$ALIGNREF)\nsummary.seqs(fasta=pipelineFiles/$ALIGNREF, processors=$PROC)\n#### Align reads\nalign.seqs(fasta=shrimp.trim.contigs.good.unique.fasta, reference=pipelineFiles/$ALIGNREF, processors=$PROC)\nsummary.seqs(fasta=shrimp.trim.contigs.good.unique.align, count=shrimp.trim.contigs.good.count_table, processors=$PROC)\n########################################################################\n#### Further processing\n########################################################################\nscreen.seqs(fasta=current, count=current, start=1, end=9583, processors=$PROC)\nsummary.seqs(fasta=current, count=current, processors=$PROC)\ncount.groups(count=current)\nfilter.seqs(fasta=current, vertical=T, trump=., processors=$PROC)\nunique.seqs(fasta=current, count=current)\nsummary.seqs(fasta=current, count=current, processors=$PROC)\n########################################################################\n#### Copy files FOR MED\n########################################################################\nsystem(cp pipelineFiles/shrimp.trim.contigs.good.unique.good.filter.unique.fasta pipelineFiles_med/)\nsystem(cp pipelineFiles/shrimp.trim.contigs.good.unique.good.filter.count_table pipelineFiles_med/)\n########################################################################\n#### Proceed with mothur workflow\n########################################################################\npre.cluster(fasta=current, count=current, diffs=2, processors=$PROC)\nsummary.seqs(fasta=current, count=current, processors=$PROC)\ncount.groups(count=current)\n########################################################################\n#### Remove Negative Control samples (files generated in R)\n########################################################################\n\n########## IN R ########################################################\n#tmp_accnos <- readr::read_delim(here(med_here, \"nc_screen/shrimp.files\"), delim = \"\\t\", col_names = FALSE)\n#tmp_accnos[, 2:3] <- NULL\n#tmp_accnos <- tmp_accnos[grepl(\"Control_\", tmp_accnos$X1), ]\n#readr::write_delim(tmp_accnos, file = here(med_here, \"nc_screen/nc_samples.accnos\"), col_names = FALSE)\n########################################################################\nget.groups(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.count_table, accnos=nc_samples.accnos)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, new=nc.fasta)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.count_table, new=nc.count_table)\nsummary.seqs(fasta=nc.fasta, count=nc.count_table, processors=$PROC)\nlist.seqs(count=nc.count_table)\ncount.seqs(count=nc.count_table, compress=f)\nget.seqs(accnos=nc.accnos, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.count_table)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, new=subset.fasta)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.count_table, new=subset.count_table)\ncount.seqs(count=subset.count_table, compress=f)\n########################################################################\n########## IN R ########################################################\n########################################################################\n#full_count_tab <- readr::read_delim(here(med_here, \"nc_screen/subset.full.count_table\"), delim = \"\\t\", col_names = TRUE)\n#control_cols     <- grep(\"^Control_\", names(full_count_tab), value = TRUE)\n#noncontrol_cols  <- setdiff(names(full_count_tab)[-(1:2)], control_cols)\n## now do the rowwise sums\n#read_totals <- full_count_tab %>%\n#  rowwise() %>%\n#  mutate(\n#    total_reads_nc   = sum(c_across(all_of(control_cols)), na.rm = TRUE),\n#    total_reads_non_nc = sum(c_across(all_of(noncontrol_cols)), na.rm = TRUE)\n#  ) %>%\n#  ungroup() %>%\n#  select(1, 2, total_reads_nc, total_reads_non_nc)\n#\n#read_totals <- read_totals %>% dplyr::rename(\"total_reads\" = 2)\n#tmp_read_totals <- read_totals %>% dplyr::mutate(perc_reads_in_nc = 100*(total_reads_nc / (total_reads_nc + total_reads_non_nc)), .after = \"total_reads_non_nc\")\n#tmp_read_totals$perc_reads_in_nc <- round(tmp_read_totals$perc_reads_in_nc, digits = 6)\n#\n#control_cols     <- grep(\"^Control_\", names(full_count_tab), value = TRUE)\n#noncontrol_cols  <- setdiff(names(full_count_tab)[-(1:2)], control_cols)\n## rowwise tally of non-zero columns\n#samp_totals <- full_count_tab %>%\n#  rowwise() %>%\n#  mutate(\n#    num_nc_samp     = sum(c_across(all_of(control_cols)) != 0, na.rm = TRUE),\n#    num_non_nc_samp = sum(c_across(all_of(noncontrol_cols)) != 0, na.rm = TRUE)\n#  ) %>%\n#  ungroup() %>%\n#  select(1, num_nc_samp, num_non_nc_samp)\n#\n#samp_totals$total_samp <- samp_totals$num_nc_samp + samp_totals$num_non_nc_samp\n#samp_totals <- samp_totals %>%  dplyr::relocate(\"total_samp\", .after = \"Representative_Sequence\")\n#samp_totals <- samp_totals %>% dplyr::mutate(perc_nc_samp = 100*( num_nc_samp / (num_nc_samp + num_non_nc_samp)), .after = \"num_non_nc_samp\")\n#\n#nc_check <- dplyr::left_join(tmp_read_totals, samp_totals, by = \"Representative_Sequence\")\n#write_delim(nc_check, here(med_here, \"nc_screen/reads_in_nc_samples.txt\"),delim = \"\\t\")\n#\n#nc_remove <- nc_check %>% filter(perc_reads_in_nc > 10 | perc_nc_samp > 10)\n#nc_remain <- dplyr::anti_join(nc_check, nc_remove)\n#rem_nc_reads <- sum(nc_remove$total_reads_nc)\n#rem_sam_reads <- sum(nc_remove$total_reads_non_nc)\n#per_reads_rem <- round(100*( rem_nc_reads / (rem_nc_reads + rem_sam_reads)), digits = 3)\n#\n#ret_nc_reads <- sum(nc_remain$total_reads_nc)\n#ret_sam_reads <- sum(nc_remain$total_reads_non_nc)\n#per_reads_ret <- round(100*( ret_nc_reads / (ret_nc_reads + ret_sam_reads)), digits = 3)\n########################################################################\nremove.seqs(accnos=nc_repseq_remove.accnos, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.count_table)\ncount.groups(count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.count_table)\n########################################################################\n########## IN R ########################################################\n########################################################################\n#tmp_before <- read_tsv(here(med_here, \"nc_screen/shrimp.trim.contigs.good.unique.good.filter.unique.precluster.count.summary\"), col_names = FALSE, col_select = 1)\n#tmp_after <- read_tsv(here(med_here, \"nc_screen/shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.count.summary\"), col_names = FALSE, col_select = 1)\n#tmp_nc_lost <- anti_join(tmp_before, tmp_after)\n#tmp_nc_lost$X1\n#\n#nc_to_remove <- semi_join(tmp_before, tmp_after)\n#nc_to_remove <- nc_to_remove %>% dplyr::filter(stringr::str_starts(X1, \"Control\"))\n# \n#readr::write_delim(nc_to_remove, file = here(med_here, \"nc_screen/nc_samples_remove.accnos\"), col_names = FALSE)\n########################################################################\nremove.groups(count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.count_table, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, accnos=nc_samples_remove.accnos)\n\n########################################\n### NEGATIVE CONTROLS Should be GONE ###\n########################################\n\nsummary.seqs(fasta=current, count=current, processors=$PROC)\ncount.groups(count=current)\nchimera.vsearch(fasta=current, count=current, dereplicate=t, processors=$PROC)\nsummary.seqs(fasta=current, count=current, processors=$PROC)\ncount.groups(count=current)\nclassify.seqs(fasta=current, count=current, reference=reference_dbs/gsrdb.fasta, taxonomy=reference_dbs/gsrdb.tax, processors=3)\nremove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Eukaryota)\nsummary.tax(taxonomy=current, count=current)\ncount.groups(count=current)\n\nchimera.vsearch(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.count_table, dereplicate=t, processors=$PROC)\nsummary.seqs(fasta=current, count=current, processors=$PROC)\ncount.groups(count=current, processors=$PROC)\n\nclassify.seqs(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.count_table, processors=$PROC, reference=reference_dbs/gsrdb.fasta, taxonomy=reference_dbs/gsrdb.tax)\n\nremove.lineage(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.count_table, taxonomy=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.gsrdb.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Eukaryota)\n\nsummary.tax(taxonomy=current, count=current)\ncount.groups(count=current, processors=$PROC)\n\n##########################\nrename.file(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.pick.count_table, taxonomy=shrimp.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.denovo.vsearch.gsrdb.wang.pick.taxonomy, prefix=final)\n\n##########################\n###    CLUSTERING      ###\n##########################\n\n##########################\n###    cluster.split   ###\n##########################\n\ncluster.split(fasta=final.fasta, count=final.count_table, taxonomy=final.taxonomy, taxlevel=4, cluster=f, processors=$PROC) \ncluster.split(file=final.file, count=final.count_table, processors=$PROC)\n\nsystem(mkdir pipelineFiles/cluster.split.gsrdb)\nsystem(mv pipelineFiles/final.opti_mcc.list pipelineFiles/cluster.split.gsrdb/)\nsystem(mv pipelineFiles/final.file pipelineFiles/cluster.split.gsrdb/)\nsystem(mv pipelineFiles/final.dist pipelineFiles/cluster.split.gsrdb/)\n\n##########################\n###    cluster         ###\n##########################\n\ndist.seqs(fasta=final.fasta, cutoff=0.03, processors=$PROC)\ncluster(column=final.dist, count=final.count_table)\n\nquit()\n\n```\n:::\n\n\nOnce you have the script and data you simply run the pipeline like so. \n\n\n::: {.cell}\n\n```{.zsh .cell-code}\nconda activate mothur\nmothur otu_batchfile_processing\n```\n:::\n\n\nIn the resources listed above, we include a table that summarizes read changes for each sample through the pipeline.\n\n:::\n\n\n::: {.column-body-outset-right}\n\n\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n#### Detailed Session Info {.appendix}\n\n{{< dstart summary=\"Expand to see Session Info\" >}}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.5.1 (2025-06-13)\n os       macOS Ventura 13.7.8\n system   x86_64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2025-10-03\n pandoc   3.6.3 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/x86_64/ (via rmarkdown)\n quarto   1.8.25 @ /Applications/quarto/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package                  * version   date (UTC) lib source\n Biobase                  * 2.68.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n BiocGenerics             * 0.54.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n Biostrings               * 2.76.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n downloadthis             * 0.5.0     2025-09-26 [1] Github (fmmattioni/downloadthis@18e3e5a)\n dplyr                    * 1.1.4     2023-11-17 [1] CRAN (R 4.5.0)\n fontawesome              * 0.5.3     2024-11-16 [1] CRAN (R 4.5.0)\n forcats                  * 1.0.0     2023-01-29 [1] CRAN (R 4.5.0)\n fs                       * 1.6.6     2025-04-12 [1] CRAN (R 4.5.0)\n generics                 * 0.1.4     2025-05-09 [1] CRAN (R 4.5.0)\n GenomeInfoDb             * 1.44.2    2025-08-18 [1] Bioconductor 3.21 (R 4.5.1)\n GenomicRanges            * 1.60.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n ggplot2                  * 4.0.0     2025-09-11 [1] CRAN (R 4.5.1)\n here                     * 1.0.2     2025-09-15 [1] CRAN (R 4.5.1)\n htmltools                * 0.5.8.1   2024-04-04 [1] CRAN (R 4.5.0)\n IRanges                  * 2.42.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n lubridate                * 1.9.4     2024-12-08 [1] CRAN (R 4.5.0)\n magrittr                 * 2.0.4     2025-09-12 [1] CRAN (R 4.5.1)\n MatrixGenerics           * 1.20.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n matrixStats              * 1.5.0     2025-01-07 [1] CRAN (R 4.5.0)\n mia                      * 1.15.6    2024-11-22 [1] Bioconductor 3.21 (R 4.5.0)\n microbiome               * 1.30.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n microeco                 * 1.15.0    2025-05-18 [1] CRAN (R 4.5.0)\n microViz                 * 0.12.7    2025-08-01 [1] https://david-barnett.r-universe.dev (R 4.5.1)\n MultiAssayExperiment     * 1.34.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n pander                   * 0.6.6     2025-03-01 [1] CRAN (R 4.5.0)\n phyloseq                 * 1.52.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n purrr                    * 1.1.0     2025-07-10 [1] CRAN (R 4.5.1)\n R.methodsS3              * 1.8.2     2022-06-13 [1] CRAN (R 4.5.0)\n R.oo                     * 1.27.1    2025-05-02 [1] CRAN (R 4.5.0)\n R.utils                  * 2.13.0    2025-02-24 [1] CRAN (R 4.5.0)\n reactable                * 0.4.4     2023-03-12 [1] CRAN (R 4.5.0)\n reactablefmtr            * 2.0.0     2022-03-16 [1] CRAN (R 4.5.0)\n readr                    * 2.1.5     2024-01-10 [1] CRAN (R 4.5.0)\n S4Vectors                * 0.46.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n seqinr                   * 4.2-36    2023-12-08 [1] CRAN (R 4.5.0)\n sessioninfo              * 1.2.3     2025-02-05 [1] CRAN (R 4.5.0)\n SingleCellExperiment     * 1.30.1    2025-05-05 [1] Bioconductor 3.21 (R 4.5.0)\n stringr                  * 1.5.2     2025-09-08 [1] CRAN (R 4.5.1)\n SummarizedExperiment     * 1.38.1    2025-04-28 [1] Bioconductor 3.21 (R 4.5.0)\n tibble                   * 3.3.0     2025-06-08 [1] CRAN (R 4.5.0)\n tidyr                    * 1.3.1     2024-01-24 [1] CRAN (R 4.5.0)\n tidyverse                * 2.0.0     2023-02-22 [1] CRAN (R 4.5.0)\n tinytable                * 0.13.0.10 2025-09-07 [1] https://vincentarelbundock.r-universe.dev (R 4.5.1)\n TreeSummarizedExperiment * 2.16.1    2025-05-08 [1] Bioconductor 3.21 (R 4.5.0)\n XVector                  * 0.48.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n zip                      * 2.3.3     2025-05-13 [1] CRAN (R 4.5.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.5-x86_64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n======   Devtools Session info   ===================================\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n package                  * version   date (UTC) lib source\n Biobase                  * 2.68.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n BiocGenerics             * 0.54.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n Biostrings               * 2.76.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n downloadthis             * 0.5.0     2025-09-26 [1] Github (fmmattioni/downloadthis@18e3e5a)\n dplyr                    * 1.1.4     2023-11-17 [1] CRAN (R 4.5.0)\n fontawesome              * 0.5.3     2024-11-16 [1] CRAN (R 4.5.0)\n forcats                  * 1.0.0     2023-01-29 [1] CRAN (R 4.5.0)\n fs                       * 1.6.6     2025-04-12 [1] CRAN (R 4.5.0)\n generics                 * 0.1.4     2025-05-09 [1] CRAN (R 4.5.0)\n GenomeInfoDb             * 1.44.2    2025-08-18 [1] Bioconductor 3.21 (R 4.5.1)\n GenomicRanges            * 1.60.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n ggplot2                  * 4.0.0     2025-09-11 [1] CRAN (R 4.5.1)\n here                     * 1.0.2     2025-09-15 [1] CRAN (R 4.5.1)\n htmltools                * 0.5.8.1   2024-04-04 [1] CRAN (R 4.5.0)\n IRanges                  * 2.42.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n lubridate                * 1.9.4     2024-12-08 [1] CRAN (R 4.5.0)\n magrittr                 * 2.0.4     2025-09-12 [1] CRAN (R 4.5.1)\n MatrixGenerics           * 1.20.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n matrixStats              * 1.5.0     2025-01-07 [1] CRAN (R 4.5.0)\n mia                      * 1.15.6    2024-11-22 [1] Bioconductor 3.21 (R 4.5.0)\n microbiome               * 1.30.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n microeco                 * 1.15.0    2025-05-18 [1] CRAN (R 4.5.0)\n microViz                 * 0.12.7    2025-08-01 [1] https://david-barnett.r-universe.dev (R 4.5.1)\n MultiAssayExperiment     * 1.34.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n pander                   * 0.6.6     2025-03-01 [1] CRAN (R 4.5.0)\n phyloseq                 * 1.52.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n purrr                    * 1.1.0     2025-07-10 [1] CRAN (R 4.5.1)\n R.methodsS3              * 1.8.2     2022-06-13 [1] CRAN (R 4.5.0)\n R.oo                     * 1.27.1    2025-05-02 [1] CRAN (R 4.5.0)\n R.utils                  * 2.13.0    2025-02-24 [1] CRAN (R 4.5.0)\n reactable                * 0.4.4     2023-03-12 [1] CRAN (R 4.5.0)\n reactablefmtr            * 2.0.0     2022-03-16 [1] CRAN (R 4.5.0)\n readr                    * 2.1.5     2024-01-10 [1] CRAN (R 4.5.0)\n S4Vectors                * 0.46.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n seqinr                   * 4.2-36    2023-12-08 [1] CRAN (R 4.5.0)\n sessioninfo              * 1.2.3     2025-02-05 [1] CRAN (R 4.5.0)\n SingleCellExperiment     * 1.30.1    2025-05-05 [1] Bioconductor 3.21 (R 4.5.0)\n stringr                  * 1.5.2     2025-09-08 [1] CRAN (R 4.5.1)\n SummarizedExperiment     * 1.38.1    2025-04-28 [1] Bioconductor 3.21 (R 4.5.0)\n tibble                   * 3.3.0     2025-06-08 [1] CRAN (R 4.5.0)\n tidyr                    * 1.3.1     2024-01-24 [1] CRAN (R 4.5.0)\n tidyverse                * 2.0.0     2023-02-22 [1] CRAN (R 4.5.0)\n tinytable                * 0.13.0.10 2025-09-07 [1] https://vincentarelbundock.r-universe.dev (R 4.5.1)\n TreeSummarizedExperiment * 2.16.1    2025-05-08 [1] Bioconductor 3.21 (R 4.5.0)\n XVector                  * 0.48.0    2025-04-15 [1] Bioconductor 3.21 (R 4.5.0)\n zip                      * 2.3.3     2025-05-13 [1] CRAN (R 4.5.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.5-x86_64/Resources/library\n * ── Packages attached to the search path.\n```\n\n\n:::\n:::\n\n\n{{< dstop >}}\n\n#### Last updated on {.appendix}\n\n2025-10-03\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}